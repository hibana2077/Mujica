### 理論依據：使用梯度影響力的有效性

1. **梯度與樣本的重要性**
   - 在模型訓練過程中，每個樣本對模型參數更新的貢獻是透過梯度計算得出的：
     $$
     \nabla \mathcal{L}(\theta; x_i, y_i) = \frac{\partial \mathcal{L}}{\partial \theta},
     $$
     其中 $ \mathcal{L} $ 是損失函數，$ \theta $ 是模型參數，$ x_i, y_i $ 是樣本。
   - 梯度的大小與方向反映了樣本對參數更新的影響力，因此梯度的統計特徵（如平均值、變異數）可以揭示樣本在訓練過程中的重要性。

2. **梯度的動態變化**
   - 在不同 Epoch 中，對同一樣本計算的梯度會隨著模型學習的進展而變化：
     - **高影響力樣本**：梯度平均值大，變異數高，表示模型對該樣本學習的過程中變化較大，對模型參數更新具有關鍵貢獻。
     - **低影響力樣本**：梯度平均值小，變異數低，表示該樣本對模型參數的影響有限，可能是冗餘或噪音樣本。

3. **梯度影響力與模型泛化**
   - 理論上，模型泛化能力受有效樣本的梯度貢獻影響。通過分析梯度影響力，可以：
     - 識別對模型更新貢獻大的 **核心樣本**（Right-Up Region）。
     - 濾除冗餘或噪音樣本，提升資料集品質，從而增強模型的泛化能力。
   - 這與 Hard Example Mining (HEM) 的思想類似，強調對模型學習過程中貢獻大的樣本給予更多關注。

4. **理論支持**
   - 梯度影響力的有效性可追溯到以下理論：
     - **SGD (Stochastic Gradient Descent)**：樣本梯度直接影響模型參數更新。
     - **影響函數 (Influence Function)**：量化單一樣本對模型損失與參數的影響。
     - **學習動態 (Training Dynamics)**：梯度變異數反映樣本在不同 Epoch 的學習穩定性。

---
**結論**：
透過統計樣本在不同 Epoch 的梯度影響力（均值、變異數與差異），能有效區分樣本的重要性，識別高影響力樣本並過濾噪音，有助於優化模型訓練和提升泛化能力。